# -*- coding: utf-8 -*-

from scrapy import Spider, Request, FormRequest
import sys
import re, os, requests, urllib
from scrapy.utils.response import open_in_browser
import time, datetime
from shutil import copyfile
import json, re, random
from realestate.items import RealestateItem

def RepresentsInt(s):
    try:
        int(s)
        return True
    except ValueError:
        return False

class selogerSpider(Spider):
    name = "spotahome"
    start_url = 'https://www.spotahome.com/paris'
    domain1 = 'https://www.spotahome.com'

    use_selenium = False
    count = 0
    pageIndex = 1
    custom_settings = {
	    'CONCURRENT_REQUESTS': 1,
	    'DOWNLOAD_DELAY': 0.3,
	    'CONCURRENT_REQUESTS_PER_DOMAIN': 1,
	    'CONCURRENT_REQUESTS_PER_IP': 1
	}

    sys.setdefaultencoding('utf-8')

    # //////// angel headers and cookies////////////
    # --------------- Get list of proxy-----------------------#
    proxy_text = requests.get('https://raw.githubusercontent.com/clarketm/proxy-list/master/proxy-list.txt').text
    list_proxy_temp = proxy_text.split('\n')
    list_proxy = []
    for line in list_proxy_temp:
        if line.strip() !='' and (line.strip()[-1] == '+' or line.strip()[-1] == '-'):
            ip = line.strip().split(':')[0].replace(' ', '')
            port = line.split(':')[-1].split(' ')[0]
            list_proxy.append('http://'+ip+':'+port)

    def start_requests(self):
        proxy = random.choice(self.list_proxy)
        yield Request(self.start_url, callback= self.parse, meta={"next_count": 1})

    def errCall(self, response):
        ban_proxy = response.request.meta['proxy']
        self.list_proxy.remove(ban_proxy)
        proxy = random.choice(self.list_proxy)
        # response.request.meta['proxy'] = proxy
        print ('err proxy: ' + proxy)
        yield Request(response.request.url,
                      callback=self.parse,
                      meta={'proxy': proxy},
                      dont_filter=True,
                      errback=self.errCall)

    def parse(self, response):
        n_list = []
        for i, t in enumerate(response.text.split('"rentableUnits":[{"id":')):
            if i == 0:
                continue
            n = t.split(',"adId":')[0]
            if n not in n_list:
                n_list.append(n)

        for n in n_list:
            url = 'https://www.spotahome.com/paris/for-rent:studios/{}'.format(n)
            time.sleep(0.3)
            yield Request(response.urljoin(url), callback=self.final_parse)

        urls = response.xpath('//div[@class="l-list__item"]/div/div/a/@href').extract()
        if len(urls) > 0:
            for url in urls:
                yield Request(response.urljoin(url), callback=self.final_parse)

            ##################_---------------- for test ----------------------##############
            # yield Request(response.urljoin(urls[0]), callback= self.final_parse, dont_filter=True)
            ###################################################################################

            next_count = response.meta['next_count'] + 1
            next_page_url = response.xpath('//a[@rel="next"]/@href').extract()
            if next_page_url:
                next_page_url = next_page_url[0]
                yield Request(response.urljoin(next_page_url), callback=self.parse, dont_filter=True, meta={"next_count": next_count})

    def final_parse(self, response):
        item = RealestateItem()

        item['online'] = 1
        item['website'] = self.name
        item['website_url'] = 'https://d26q4asbryw2nm.cloudfront.net/2390803/bundles/sahapp/favicon/largetile.png'
        item['url'] = response.url
        item['description'] = ''
        title = response.xpath('//div[@class="property-title-section"]/h1/text()').extract_first()
        if title:
            item['title'] = title

            price = response.xpath('//span[@class="rentable-unit-price"]/text()').re(r'[\d.,]+')
            if price:
                try:
                    price = ''.join(price)
                    item['price'] = price.replace(',', '.')
                except:
                    pass

            item['city'] = response.url.split('https://www.spotahome.com/')[-1].split('/')[0]

            district = response.xpath('//div[@class="property-title-section"]/h1/text()').re(r'[\d.,]+')
            if district:
                try:
                    item['district'] = int(district[-1].replace(',', ''))
                except:
                    pass
            addr = response.xpath('//section[@class="l-main-section l-property-main-section"]/div/div[@class="breadcrumb"]/span/text()').extract()
            if addr:
                item['address'] = addr[-1]

            avaiable_from = response.xpath('//div[@class="room--availability ga-detail-room-availability"]/text()').extract_first()
            if avaiable_from:
                avaiable_from = avaiable_from.split('Available: ')[-1]
                if avaiable_from:
                    avaiable_from = avaiable_from

            # addr = response.xpath('//div[@itemprop="address"]/p/text()').extract_first()
            # if addr:
            #     addr = addr.split(' ')
            #     item['city'] = addr[0]
            #
            #     district = response.xpath('//div[@itemprop="address"]/p/text()').re(r'[\d.,]+')
            #     if len(district) > 1:
            #         item['district'] = district[-1]

            images = response.xpath('//meta[@itemprop="image"]/@content').extract()
            if images:
                new_imgs = []
                for img in images:
                    img = img.strip()
                    if img:
                        new_imgs.append(img)
                if new_imgs:
                    item['images'] = ','.join(new_imgs)

            # area = response.xpath('//div[@class="left-panel"]//div[@class="btn btn-default btn-rounded btn-top-cover-default bold btn-shadow"]/text()').re(r'[\d.,]+')
            # if area:
            #     area = area[-1].replace(',', '.')
            #     item['size'] = area

            furnished = response.xpath('//div[@class="AvailableRoomFeatures"]/text()').extract_first()
            if furnished == 'Furnished':
                item['furnished'] = 1

            # temp = response.xpath('//div[@class="left-panel"]/p/text()').extract()
            # for t in temp:
            #     if 'Disponibilit√©' in t:
            #         avaiable_deposit = t.split(' ')[-1]

            descs = response.text.split('"description":"')
            if descs:
                new_desc = []
                for d in descs:
                    if d[:3] == '<p>':
                        d = d.split('"')[0]
                        d = d.strip().replace('</p>', '')
                        ds = d.split('<p>')
                        for dd in ds:
                            dd = dd.strip()
                            if dd:
                                new_desc.append(dd)
                        break
                if new_desc:
                    item['description'] = '\n'.join(new_desc)

            if 'Property type:' in response.text:
                type1 = response.text.split('Property type:')[-1].split('</li>')[0]
                if type1:
                    item['type'] = type1.strip()

            if 'Floor area:' in response.text:
                area = response.text.split('Floor area:')[-1].split('</li>')[0]
                if area:
                    area = re.findall('[\d.,]+', area)
                    if area:
                        area = area[0].replace(',', '.')
                        item['size'] = area
            if 'Floor:' in response.text:
                floor = response.text.split('Floor:')[-1].split('</li>')[0]
                if floor:
                    floor = re.findall('[\d.,]+', floor)
                    if floor:
                        floor = floor[0]
                        item['floor'] = floor
            if 'Number of bathrooms:' in response.text:
                bathrooms = response.text.split('Number of bathrooms:')[-1].split('</li>')[0]
                if bathrooms:
                    bathrooms = bathrooms.strip()

            self.count += 1
            print("Total Count: " + str(self.count))
            item['rent_buy'] = 'rent'
            yield item